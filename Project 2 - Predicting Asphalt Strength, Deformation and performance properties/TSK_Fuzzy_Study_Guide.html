<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>TSK Fuzzy System for Asphalt Prediction — Study Guide</title>
<style>
:root{--bg:#0d1117;--bg2:#161b22;--bg3:#1c2330;--bgs:#0e1218;--brd:#30363d;--tx:#e6edf3;--txd:#8b949e;--txb:#f0f6fc;--ac:#58a6ff;--ac2:#3fb950;--ac3:#d2a8ff;--ac4:#f0883e;--ac5:#ff7b72;--ac6:#79c0ff;--sw:280px;--fb:'Segoe UI',system-ui,sans-serif;--fc:'Cascadia Code','Fira Code','Consolas',monospace}
*,*::before,*::after{box-sizing:border-box;margin:0;padding:0}
html{scroll-behavior:smooth;scrollbar-color:var(--brd) var(--bg)}
body{font-family:var(--fb);background:var(--bg);color:var(--tx);line-height:1.75;font-size:16px}
#sidebar{position:fixed;top:0;left:0;width:var(--sw);height:100vh;background:var(--bgs);border-right:1px solid var(--brd);overflow-y:auto;z-index:100;padding:20px 0;scrollbar-width:thin}
#sidebar::-webkit-scrollbar{width:4px}
#sidebar::-webkit-scrollbar-thumb{background:var(--brd);border-radius:4px}
.sidebar-title{padding:0 20px 16px;font-size:14px;font-weight:700;color:var(--ac);text-transform:uppercase;letter-spacing:1.5px;border-bottom:1px solid var(--brd);margin-bottom:12px}
.nav-group{padding:8px 0}
.nav-group-label{padding:4px 20px;font-size:11px;font-weight:600;color:var(--txd);text-transform:uppercase;letter-spacing:1px}
.nav-item{display:flex;align-items:flex-start;gap:10px;padding:7px 20px;text-decoration:none;color:var(--txd);font-size:13.5px;line-height:1.4;transition:all .2s;cursor:pointer;border-left:3px solid transparent}
.nav-item:hover{color:var(--tx);background:#ffffff08;border-left-color:var(--ac)}
.nav-check{flex-shrink:0;width:16px;height:16px;border:2px solid var(--brd);border-radius:4px;margin-top:2px;cursor:pointer;transition:all .2s;display:flex;align-items:center;justify-content:center;background:transparent}
.nav-check.checked{background:var(--ac2);border-color:var(--ac2)}
.nav-check.checked::after{content:'\2713';color:#fff;font-size:11px;font-weight:700}
#progress-bar-wrap{margin:16px 20px;background:var(--bg3);border-radius:6px;height:8px;overflow:hidden}
#progress-bar{height:100%;background:linear-gradient(90deg,var(--ac),var(--ac2));width:0%;transition:width .5s;border-radius:6px}
#progress-text{padding:0 20px;font-size:12px;color:var(--txd);margin-bottom:8px}
#back-to-top{display:block;margin:16px 20px;padding:8px;background:var(--bg3);border:1px solid var(--brd);border-radius:6px;color:var(--txd);font-size:12px;text-align:center;cursor:pointer;transition:all .2s;text-decoration:none}
#back-to-top:hover{color:var(--ac);border-color:var(--ac)}
#main{margin-left:var(--sw);max-width:900px;padding:40px 50px 120px}
h1{font-size:2.4em;font-weight:800;background:linear-gradient(135deg,var(--ac),var(--ac3));-webkit-background-clip:text;-webkit-text-fill-color:transparent;background-clip:text;margin-bottom:8px;line-height:1.2}
h1+.subtitle{font-size:1.1em;color:var(--txd);margin-bottom:48px;border-bottom:1px solid var(--brd);padding-bottom:32px}
h2{font-size:1.6em;font-weight:700;color:var(--txb);margin-top:56px;margin-bottom:16px;padding-bottom:10px;border-bottom:2px solid var(--ac);display:flex;align-items:center;gap:12px}
.sn{display:inline-flex;align-items:center;justify-content:center;width:36px;height:36px;background:var(--ac);color:var(--bg);border-radius:50%;font-size:16px;font-weight:800;flex-shrink:0}
h3{font-size:1.2em;color:var(--ac3);margin-top:32px;margin-bottom:12px}
h4{font-size:1.05em;color:var(--ac4);margin-top:24px;margin-bottom:8px}
p{margin-bottom:14px}
.bx{border-radius:10px;padding:20px 24px;margin:20px 0;border-left:4px solid}
.bx-c{background:#58a6ff0a;border-color:var(--ac)}.bx-w{background:#3fb9500a;border-color:var(--ac2)}.bx-n{background:#f0883e0a;border-color:var(--ac4)}.bx-k{background:#d2a8ff0a;border-color:var(--ac3)}
.bt{font-weight:700;font-size:14px;text-transform:uppercase;letter-spacing:.8px;margin-bottom:8px}
.bx-c .bt{color:var(--ac)}.bx-w .bt{color:var(--ac2)}.bx-n .bt{color:var(--ac4)}.bx-k .bt{color:var(--ac3)}
.cw{margin:16px 0 24px;border-radius:10px;overflow:hidden;border:1px solid var(--brd)}
.ch{display:flex;justify-content:space-between;align-items:center;padding:8px 16px;background:#21262d;border-bottom:1px solid var(--brd);font-size:13px;color:var(--txd)}
.cf{font-weight:600;color:var(--ac6)}.cl{font-style:italic}
pre{background:var(--bg3);padding:20px;overflow-x:auto;font-family:var(--fc);font-size:13.5px;line-height:1.6;color:#e6edf3;margin:0}
code{font-family:var(--fc);font-size:.9em;background:var(--bg3);padding:2px 6px;border-radius:4px;color:var(--ac6)}
pre code{background:none;padding:0;font-size:inherit;color:inherit}
.kw{color:#ff7b72}.fn{color:#d2a8ff}.st{color:#a5d6ff}.cm{color:#8b949e;font-style:italic}.nu{color:#79c0ff}.op{color:#ff7b72}
details{margin:16px 0;border:1px solid var(--brd);border-radius:10px;overflow:hidden}
details[open]{border-color:var(--ac)}
summary{padding:14px 20px;background:var(--bg2);cursor:pointer;font-weight:600;color:var(--ac);user-select:none;list-style:none;display:flex;align-items:center;gap:10px;transition:background .2s}
summary:hover{background:#1c2230}
summary::before{content:'\25B8';font-size:14px;transition:transform .2s;color:var(--ac)}
details[open] summary::before{transform:rotate(90deg)}
summary::-webkit-details-marker{display:none}
.db{padding:20px 24px;background:var(--bg)}
.dg{margin:24px 0;padding:24px;background:var(--bg2);border:1px solid var(--brd);border-radius:10px;text-align:center}
.dg svg{max-width:100%;height:auto}
.dc{margin-top:12px;font-size:13px;color:var(--txd);font-style:italic}
table{width:100%;border-collapse:collapse;margin:16px 0;font-size:14px}
th{background:var(--bg2);color:var(--ac);padding:10px 14px;text-align:left;border-bottom:2px solid var(--ac);font-weight:600}
td{padding:10px 14px;border-bottom:1px solid var(--brd)}
tr:hover td{background:#ffffff04}
.math{display:block;text-align:center;padding:16px;margin:16px 0;background:var(--bg2);border-radius:10px;font-family:var(--fc);font-size:15px;color:var(--ac3);border:1px solid var(--brd);overflow-x:auto}
@media(max-width:900px){:root{--sw:0px}#sidebar{display:none}#main{padding:24px 20px 80px}h1{font-size:1.8em}}
.tg{display:inline-block;padding:2px 8px;border-radius:4px;font-size:12px;font-weight:600}
.tg-i{background:#58a6ff22;color:var(--ac)}.tg-o{background:#3fb95022;color:var(--ac2)}.tg-f{background:#d2a8ff22;color:var(--ac3)}
.an{padding:16px 20px;margin:14px 0;background:#f0883e08;border-radius:10px;border:1px dashed var(--ac4);font-size:15px}
.an::before{content:'\1F4A1 '}
.ft{font-family:var(--fc);font-size:13px;line-height:1.8;padding:16px 20px;background:var(--bg3);border-radius:10px;border:1px solid var(--brd);color:var(--txd)}
.ft .d{color:var(--ac);font-weight:600}.ft .f{color:var(--ac3)}.ft .ds{color:var(--txd);font-style:italic;font-family:var(--fb)}
</style>
</head>
<body>
<nav id="sidebar">
<div class="sidebar-title">&#128218; Study Progress</div>
<div id="progress-text">0 / 12 complete</div>
<div id="progress-bar-wrap"><div id="progress-bar"></div></div>
<div class="nav-group">
<div class="nav-group-label">Overview</div>
<a class="nav-item" href="#s0"><span class="nav-check" data-idx="0"></span><span>The Problem</span></a>
<a class="nav-item" href="#s1"><span class="nav-check" data-idx="1"></span><span>Big Picture</span></a>
<a class="nav-item" href="#s2"><span class="nav-check" data-idx="2"></span><span>The Dataset</span></a>
</div>
<div class="nav-group">
<div class="nav-group-label">Theory</div>
<a class="nav-item" href="#s3"><span class="nav-check" data-idx="3"></span><span>Fuzzy Sets &amp; MFs</span></a>
<a class="nav-item" href="#s4"><span class="nav-check" data-idx="4"></span><span>TSK Rules</span></a>
<a class="nav-item" href="#s5"><span class="nav-check" data-idx="5"></span><span>Subtractive Clustering</span></a>
<a class="nav-item" href="#s6"><span class="nav-check" data-idx="6"></span><span>Hybrid Learning</span></a>
</div>
<div class="nav-group">
<div class="nav-group-label">Implementation</div>
<a class="nav-item" href="#s7"><span class="nav-check" data-idx="7"></span><span>Project Structure</span></a>
<a class="nav-item" href="#s8"><span class="nav-check" data-idx="8"></span><span>Code Walkthrough</span></a>
<a class="nav-item" href="#s9"><span class="nav-check" data-idx="9"></span><span>Training Pipeline</span></a>
</div>
<div class="nav-group">
<div class="nav-group-label">Results</div>
<a class="nav-item" href="#s10"><span class="nav-check" data-idx="10"></span><span>Results &amp; RMSE</span></a>
<a class="nav-item" href="#s11"><span class="nav-check" data-idx="11"></span><span>How to Run</span></a>
</div>
<a id="back-to-top" href="#top">&uarr; Back to Top</a>
</nav>

<main id="main">
<div id="top"></div>
<h1>Predicting Asphalt Properties with TSK Fuzzy Systems</h1>
<p class="subtitle">A complete, step-by-step guide &mdash; from theory to working Python code. By the end you will understand every piece and be able to rebuild it from scratch.</p>

<h2 id="s0"><span class="sn">0</span> What Problem Are We Solving?</h2>
<p>Roads are built with <strong>asphalt</strong> &mdash; a mixture of sticky binder (bitumen) and crushed stone (aggregates). Before building a road, engineers test the asphalt to ensure it is strong, not too stiff, not too soft. These lab tests are expensive and slow.</p>
<div class="bx bx-c"><div class="bt">&#128142; Core Idea</div><p>We want to <strong>predict</strong> the test results from the recipe of the mix &mdash; without running the expensive lab tests every time.</p></div>
<p>We predict <strong>four properties</strong>:</p>
<table><tr><th>Output</th><th>What It Measures</th><th>Unit</th></tr>
<tr><td><span class="tg tg-o">Stability</span></td><td>Maximum load (strength)</td><td>kN</td></tr>
<tr><td><span class="tg tg-o">Flow</span></td><td>Deformation at max load</td><td>mm</td></tr>
<tr><td><span class="tg tg-o">ITSM 20&deg;C</span></td><td>Stiffness at moderate temperature</td><td>MPa</td></tr>
<tr><td><span class="tg tg-o">ITSM 30&deg;C</span></td><td>Stiffness at hot temperature</td><td>MPa</td></tr></table>
<div class="an">Think of it like predicting how a cake will taste from the recipe &mdash; without baking it first.</div>
<p>Our tool: a <strong>TSK Fuzzy Inference System</strong> &mdash; a mathematical model using "fuzzy" (imprecise, human-like) rules to make predictions.</p>

<h2 id="s1"><span class="sn">1</span> The Big Picture</h2>
<div class="dg">
<svg viewBox="0 0 780 200" xmlns="http://www.w3.org/2000/svg" style="font-family:Segoe UI,sans-serif">
<defs><marker id="ah" markerWidth="8" markerHeight="8" refX="8" refY="4" orient="auto"><path d="M0,0 L8,4 L0,8" fill="#8b949e"/></marker></defs>
<rect x="5" y="60" width="120" height="70" rx="10" fill="#1c2330" stroke="#58a6ff" stroke-width="2"/><text x="65" y="90" text-anchor="middle" fill="#58a6ff" font-weight="700" font-size="12">&#128202; Excel Data</text><text x="65" y="110" text-anchor="middle" fill="#8b949e" font-size="10">168 &times; 14</text>
<rect x="155" y="60" width="110" height="70" rx="10" fill="#1c2330" stroke="#3fb950" stroke-width="2"/><text x="210" y="90" text-anchor="middle" fill="#3fb950" font-weight="700" font-size="11">&#128256; Split</text><text x="210" y="110" text-anchor="middle" fill="#8b949e" font-size="10">80/20</text>
<rect x="295" y="60" width="110" height="70" rx="10" fill="#1c2330" stroke="#d2a8ff" stroke-width="2"/><text x="350" y="90" text-anchor="middle" fill="#d2a8ff" font-weight="700" font-size="11">&#128207; Normalise</text><text x="350" y="110" text-anchor="middle" fill="#8b949e" font-size="10">[0, 1]</text>
<rect x="435" y="20" width="130" height="60" rx="10" fill="#1c2330" stroke="#f0883e" stroke-width="2"/><text x="500" y="48" text-anchor="middle" fill="#f0883e" font-weight="700" font-size="11">&#127919; Clustering</text><text x="500" y="65" text-anchor="middle" fill="#8b949e" font-size="10">&rarr; discover rules</text>
<rect x="435" y="100" width="130" height="60" rx="10" fill="#1c2330" stroke="#ff7b72" stroke-width="2"/><text x="500" y="128" text-anchor="middle" fill="#ff7b72" font-weight="700" font-size="11">&#9881; Hybrid Tuning</text><text x="500" y="148" text-anchor="middle" fill="#8b949e" font-size="10">LSE + Gradient</text>
<rect x="595" y="60" width="80" height="70" rx="10" fill="#1c2330" stroke="#58a6ff" stroke-width="2"/><text x="635" y="90" text-anchor="middle" fill="#58a6ff" font-weight="700" font-size="11">4&times;TSK</text><text x="635" y="108" text-anchor="middle" fill="#8b949e" font-size="10">systems</text>
<rect x="700" y="60" width="70" height="70" rx="10" fill="#1c2330" stroke="#3fb950" stroke-width="2"/><text x="735" y="90" text-anchor="middle" fill="#3fb950" font-weight="700" font-size="11">&#128200; RMSE</text><text x="735" y="108" text-anchor="middle" fill="#8b949e" font-size="10">evaluate</text>
<line x1="125" y1="95" x2="153" y2="95" stroke="#8b949e" stroke-width="2" marker-end="url(#ah)"/>
<line x1="265" y1="95" x2="293" y2="95" stroke="#8b949e" stroke-width="2" marker-end="url(#ah)"/>
<line x1="405" y1="80" x2="433" y2="55" stroke="#8b949e" stroke-width="2" marker-end="url(#ah)"/>
<line x1="405" y1="100" x2="433" y2="125" stroke="#8b949e" stroke-width="2" marker-end="url(#ah)"/>
<line x1="500" y1="80" x2="500" y2="98" stroke="#8b949e" stroke-width="2" marker-end="url(#ah)"/>
<line x1="565" y1="50" x2="593" y2="85" stroke="#8b949e" stroke-width="1.5" marker-end="url(#ah)"/>
<line x1="565" y1="130" x2="593" y2="100" stroke="#8b949e" stroke-width="1.5" marker-end="url(#ah)"/>
<line x1="675" y1="95" x2="698" y2="95" stroke="#8b949e" stroke-width="2" marker-end="url(#ah)"/>
</svg>
<div class="dc">Figure 1 &mdash; System architecture: data flows left-to-right through normalisation, rule discovery, hybrid tuning, and evaluation.</div>
</div>
<div class="bx bx-w"><div class="bt">&#129300; Why four separate systems?</div><p>Each output has a different relationship with the inputs. By building four independent TSK systems, each can have its own rules tuned specifically for its target.</p></div>

<h2 id="s2"><span class="sn">2</span> Understanding the Dataset</h2>
<p>The Excel file contains <strong>168 asphalt specimens</strong> (rows) with 14 columns:</p>
<h3>10 Inputs <span class="tg tg-i">INPUT</span></h3>
<table><tr><th>#</th><th>Variable</th><th>Meaning</th></tr>
<tr><td>1</td><td><code>Viscosity</code></td><td>How thick the binder is (Pa&middot;s). Higher = stiffer.</td></tr>
<tr><td>2</td><td><code>Pb</code></td><td>Total asphalt cement content by weight.</td></tr>
<tr><td>3</td><td><code>Pbe</code></td><td>Effective binder &mdash; the part that actually glues things.</td></tr>
<tr><td>4</td><td><code>Gmm</code></td><td>Max theoretical specific gravity (density with zero air).</td></tr>
<tr><td>5</td><td><code>Va</code></td><td>% Air voids. Target: 3&ndash;5%. Too low = bleeding, too high = cracking.</td></tr>
<tr><td>6</td><td><code>Unit Weight</code></td><td>Bulk density (kg/m&sup3;). Higher = better compaction.</td></tr>
<tr><td>7</td><td><code>P200</code></td><td>Mineral filler content (% passing 0.075&nbsp;mm).</td></tr>
<tr><td>8</td><td><code>P4</code></td><td>Coarse aggregate content.</td></tr>
<tr><td>9</td><td><code>P38</code></td><td>Coarse aggregate skeleton.</td></tr>
<tr><td>10</td><td><code>P34</code></td><td>Largest aggregate fraction.</td></tr></table>
<div class="bx bx-n"><div class="bt">&#9888;&#65039; Excel File Structure</div><p>Row 1 = group labels, Row 2 = column names, Row 3 = descriptions. <strong>Data starts at Row 4.</strong> Our <code>data_loader.py</code> handles this by skipping the first 3 rows.</p></div>

<h2 id="s3"><span class="sn">3</span> Fuzzy Sets &amp; Membership Functions</h2>
<p>In everyday life we use imprecise words: "low viscosity", "high air voids". Classical logic forces a hard boundary. Fuzzy logic allows <strong>partial membership</strong>.</p>
<div class="an">At 40&deg;C, is water "warm" or "hot"? In fuzzy logic it can be <strong>70% warm</strong> and <strong>30% hot</strong> simultaneously.</div>
<h3>Gaussian Membership Function</h3>
<div class="math">&mu;(x; c, &sigma;) = exp( &minus;0.5 &times; ((x &minus; c) / &sigma;)&sup2; )</div>
<p><strong>c</strong> = centre (peak, where membership = 1.0); <strong>&sigma;</strong> = spread (how wide the bell is). Both are <em>learnable</em> &mdash; training adjusts them to fit the data.</p>
<div class="dg">
<svg viewBox="0 0 500 200" xmlns="http://www.w3.org/2000/svg" style="font-family:Segoe UI,sans-serif">
<line x1="50" y1="170" x2="470" y2="170" stroke="#8b949e" stroke-width="2"/>
<line x1="50" y1="170" x2="50" y2="20" stroke="#8b949e" stroke-width="2"/>
<text x="260" y="195" text-anchor="middle" fill="#8b949e" font-size="12">Input x</text>
<text x="40" y="175" text-anchor="end" fill="#8b949e" font-size="10">0</text>
<text x="40" y="28" text-anchor="end" fill="#8b949e" font-size="10">1</text>
<path d="M50,170 Q90,168 120,155 Q150,125 165,70 Q175,35 180,25 Q185,35 195,70 Q210,125 240,155 Q270,168 310,170" fill="none" stroke="#58a6ff" stroke-width="2.5"/>
<text x="180" y="18" text-anchor="middle" fill="#58a6ff" font-weight="700" font-size="12">LOW</text>
<path d="M170,170 Q210,168 240,155 Q270,125 285,70 Q295,35 300,25 Q305,35 315,70 Q330,125 360,155 Q390,168 430,170" fill="none" stroke="#3fb950" stroke-width="2.5"/>
<text x="300" y="18" text-anchor="middle" fill="#3fb950" font-weight="700" font-size="12">MED</text>
<path d="M280,170 Q320,168 350,155 Q380,125 395,70 Q405,35 410,25 Q415,35 425,70 Q440,125 460,155 Q470,168 470,170" fill="none" stroke="#f0883e" stroke-width="2.5"/>
<text x="410" y="18" text-anchor="middle" fill="#f0883e" font-weight="700" font-size="12">HIGH</text>
<circle cx="240" cy="120" r="5" fill="#ff7b72" stroke="#fff" stroke-width="2"/>
<text x="255" y="115" fill="#ff7b72" font-size="10">x: &mu;Low=0.3, &mu;Med=0.7</text>
</svg>
<div class="dc">Figure 2 &mdash; Three Gaussian MFs. The red dot at x shows partial membership in both "Low" and "Medium".</div>
</div>

<details><summary>&#128196; View Code &mdash; membership_functions.py</summary><div class="db">
<p>Defines the Gaussian MF and a <code>FuzzyVariable</code> class storing linguistic terms.</p>
<div class="cw"><div class="ch"><span class="cf">membership_functions.py</span><span class="cl">Python</span></div>
<pre><code><span class="cm"># Gaussian MF: Mendel (2017, Ch.2), Klir &amp; Yuan (1995, &sect;2.3)</span>
<span class="kw">import</span> numpy <span class="kw">as</span> np

<span class="kw">def</span> <span class="fn">gaussian_mf</span>(x, c, sigma):
    sigma = max(sigma, 1e-10)  <span class="cm"># prevent /0</span>
    <span class="kw">return</span> np.exp(-0.5 * ((x - c) / sigma) ** 2)

<span class="kw">class</span> FuzzyVariable:
    <span class="kw">def</span> <span class="fn">__init__</span>(self, name):
        self.name = name
        self.terms = []  <span class="cm"># [(label, c, sigma), ...]</span>
    <span class="kw">def</span> <span class="fn">add_term</span>(self, label, c, sigma):
        self.terms.append((label, c, sigma))
    <span class="kw">def</span> <span class="fn">fuzzify</span>(self, x):
        <span class="kw">return</span> {l: gaussian_mf(x,c,s) <span class="kw">for</span> l,c,s <span class="kw">in</span> self.terms}</code></pre></div>
<p><code>max(sigma, 1e-10)</code> guards against division-by-zero if sigma ever becomes zero during training.</p>
</div></details>

<h2 id="s4"><span class="sn">4</span> TSK Rules: The Brain of the System</h2>
<div class="bx bx-c"><div class="bt">&#128208; TSK Rule (First-Order)</div>
<p><strong>IF</strong> Viscosity is <em>Low</em> <strong>AND</strong> AirVoids is <em>High</em> <strong>AND</strong> &hellip;<br>
<strong>THEN</strong> Stability = p&sub0; + p&sub1;&middot;Viscosity + p&sub2;&middot;AirVoids + &hellip; + p&sub1;&sub0;&middot;P34</p></div>
<p>The <strong>IF</strong> part uses fuzzy MFs. The <strong>THEN</strong> part is a <em>linear equation</em> producing a crisp number.</p>
<h3>How Rules Combine</h3>
<div class="math">w_k = &mu;&sub1;k(x&sub1;) &times; &mu;&sub2;k(x&sub2;) &times; &hellip; &times; &mu;&sub1;&sub0;k(x&sub1;&sub0;) &nbsp;&nbsp;(firing strength)</div>
<div class="math">y_k = p&sub0;k + p&sub1;k&middot;x&sub1; + &hellip; + p&sub1;&sub0;k&middot;x&sub1;&sub0; &nbsp;&nbsp;(rule output)</div>
<div class="math">&ycirc; = &Sigma;k (wk &middot; yk) / &Sigma;k wk &nbsp;&nbsp;(weighted average = final prediction)</div>
<div class="an">Think of 12 experts. Each specialises in certain asphalt types (their fuzzy antecedent). For a given sample, confident experts carry more weight. The answer is a confidence-weighted average.</div>

<details><summary>&#128196; View Code &mdash; tsk_system.py (core engine)</summary><div class="db">
<p><code>TSKRule</code> stores MF params + linear coefficients. <code>TSKSystem</code> collects rules, predicts, and fits consequents via LSE.</p>
<div class="cw"><div class="ch"><span class="cf">tsk_system.py</span><span class="cl">Python</span></div>
<pre><code><span class="kw">class</span> TSKRule:
    <span class="kw">def</span> <span class="fn">firing_strength</span>(self, X):
        w = np.ones(X.shape[0])
        <span class="kw">for</span> j <span class="kw">in</span> range(X.shape[1]):
            w *= gaussian_mf(X[:,j], self.antecedent_centres[j],
                             self.antecedent_sigmas[j])
        <span class="kw">return</span> w  <span class="cm"># product t-norm</span>

    <span class="kw">def</span> <span class="fn">consequent_output</span>(self, X):
        X_aug = np.hstack([np.ones((X.shape[0],1)), X])
        <span class="kw">return</span> X_aug @ self.consequent_params

<span class="kw">class</span> TSKSystem:
    <span class="kw">def</span> <span class="fn">predict</span>(self, X):
        num = den = np.zeros(X.shape[0])
        <span class="kw">for</span> rule <span class="kw">in</span> self.rules:
            w = rule.firing_strength(X)
            num += w * rule.consequent_output(X)
            den += w
        <span class="kw">return</span> num / np.maximum(den, 1e-12)

    <span class="kw">def</span> <span class="fn">fit_consequents_lse</span>(self, X, y):
        <span class="cm"># Builds design matrix A, solves P = (A'A+&lambda;I)^{-1} A'y</span>
        <span class="cm"># Ridge regression with &lambda;=0.01 prevents overfitting</span>
        ...</code></pre></div>
<p><strong>Why ridge (&lambda;=0.01)?</strong> With ~12 rules &times; 11 params = 132 unknowns but only 134 training samples, plain least-squares overfits. Ridge adds a small penalty that stabilises the solution.</p>
</div></details>

<h2 id="s5"><span class="sn">5</span> Subtractive Clustering: Discovering Rules</h2>
<p>How many rules should we have? We let the <strong>data tell us</strong> via subtractive clustering (Chiu 1994; Mendel 2017, &sect;9.4).</p>
<h3>Algorithm</h3>
<p><strong>Step 1.</strong> Each data point gets a "potential" proportional to the density of neighbours:</p>
<div class="math">P_i = &Sigma;j exp(&minus;4 &middot; ||z_i &minus; z_j||&sup2; / r_a&sup2;)</div>
<p><strong>Step 2.</strong> Pick the densest point as the first cluster centre.</p>
<p><strong>Step 3.</strong> Reduce potentials near the centre (radius r_b = 1.25 &times; r_a) so we don't pick a duplicate.</p>
<p><strong>Step 4.</strong> Repeat until remaining potential is too low.</p>
<div class="bx bx-w"><div class="bt">&#129300; Why r_a = 1.2?</div><p>With r_a=0.5 we get ~35 rules &mdash; too many, causes overfitting. r_a=1.2 yields ~11&ndash;12 rules, a good balance between capacity and generalisation.</p></div>

<details><summary>&#128196; View Code &mdash; clustering.py</summary><div class="db">
<div class="cw"><div class="ch"><span class="cf">clustering.py</span><span class="cl">Python</span></div>
<pre><code><span class="kw">def</span> <span class="fn">subtractive_clustering</span>(data, ra, squash_factor, accept_ratio, reject_ratio):
    N, D = data.shape
    rb = squash_factor * ra
    alpha, beta = 4.0/ra**2, 4.0/rb**2

    <span class="cm"># Step 1: compute potentials</span>
    potentials = np.zeros(N)
    <span class="kw">for</span> i <span class="kw">in</span> range(N):
        dists_sq = np.sum((data - data[i])**2, axis=1)
        potentials[i] = np.sum(np.exp(-alpha * dists_sq))

    centres = []
    first_potential = potentials.max()
    <span class="kw">while</span> True:
        best_idx = np.argmax(potentials)
        best_pot = potentials[best_idx]
        ratio = best_pot / first_potential <span class="kw">if</span> centres <span class="kw">else</span> 1.0
        <span class="kw">if</span> ratio &gt; accept_ratio <span class="kw">or not</span> centres:
            centres.append(data[best_idx].copy())
        <span class="kw">elif</span> ratio &lt; reject_ratio:
            <span class="kw">break</span>
        <span class="cm"># ... grey-zone logic omitted for brevity</span>
        <span class="cm"># Reduce potentials near new centre</span>
        dists_sq = np.sum((data - centres[-1])**2, axis=1)
        potentials -= best_pot * np.exp(-beta * dists_sq)
        potentials = np.maximum(potentials, 0.0)
    <span class="kw">return</span> np.array(centres)</code></pre></div>
</div></details>

<h2 id="s6"><span class="sn">6</span> Hybrid Learning: Tuning Parameters</h2>
<p>Two parameter types need optimising:</p>
<table><tr><th>Type</th><th>Where</th><th>Method</th></tr>
<tr><td><strong>Consequent</strong> (p&sub0;, p&sub1;&hellip;)</td><td>THEN part</td><td>Least-Squares (one-shot)</td></tr>
<tr><td><strong>Antecedent</strong> (c, &sigma;)</td><td>IF part (MFs)</td><td>Gradient Descent</td></tr></table>
<p>Each epoch: <strong>Phase A</strong> &mdash; fix antecedent, solve LSE for consequents. <strong>Phase B</strong> &mdash; fix consequents, gradient-descent the antecedent. Repeat up to 800 epochs until convergence.</p>
<div class="an">Like tuning a radio: LSE coarsely finds the station; gradient descent fine-tunes for the clearest signal.</div>

<details><summary>&#128196; View Code &mdash; training.py (hybrid loop)</summary><div class="db">
<div class="cw"><div class="ch"><span class="cf">training.py</span><span class="cl">Python</span></div>
<pre><code><span class="kw">def</span> <span class="fn">tune_tsk_system</span>(system, X_train, y_train_col, lr, max_epochs, tol):
    <span class="kw">for</span> epoch <span class="kw">in</span> range(max_epochs):
        y_pred = system.predict(X_train)
        error = y_train_col - y_pred
        rmse_val = np.sqrt(np.mean(error**2))
        <span class="kw">if</span> converged: <span class="kw">break</span>

        <span class="cm"># Phase B: gradient descent on antecedent</span>
        W = system.get_all_firing_strengths(X_train)
        W_bar = W / W.sum(axis=1, keepdims=True)
        <span class="kw">for</span> k, rule <span class="kw">in</span> enumerate(system.rules):
            <span class="kw">for</span> j <span class="kw">in</span> range(n_inputs):
                <span class="cm"># Gradient for centre c_{jk}</span>
                dw_dc = w_k * (x_j - c_jk) / s_jk**2
                rule.antecedent_centres[j] -= lr * np.mean(dE_dw * dw_dc)
                <span class="cm"># Gradient for spread &sigma;_{jk}</span>
                dw_ds = w_k * (x_j - c_jk)**2 / s_jk**3
                rule.antecedent_sigmas[j] -= lr * np.mean(dE_dw * dw_ds)

        <span class="cm"># Phase A: re-estimate consequents after antecedent change</span>
        system.fit_consequents_lse(X_train, y_train_col)
    <span class="kw">return</span> history</code></pre></div>
<p><strong>Why re-run LSE every epoch?</strong> After moving antecedent params, the firing strengths change, so old consequent values are stale. Re-solving LSE (one matrix operation) keeps consequents always optimal.</p>
</div></details>

<h2 id="s7"><span class="sn">7</span> Project Structure: Every File Explained</h2>
<div class="ft">
<span class="d">asphalt_tsk_project/</span><br>
&boxvr;&horbar; <span class="f">config.py</span> <span class="ds">&larr; All settings (paths, hyperparams). No logic.</span><br>
&boxvr;&horbar; <span class="f">data_loader.py</span> <span class="ds">&larr; Reads Excel, splits train/test, normalises [0,1].</span><br>
&boxvr;&horbar; <span class="f">membership_functions.py</span> <span class="ds">&larr; Gaussian MF + FuzzyVariable class.</span><br>
&boxvr;&horbar; <span class="f">clustering.py</span> <span class="ds">&larr; Subtractive clustering algorithm.</span><br>
&boxvr;&horbar; <span class="f">tsk_system.py</span> <span class="ds">&larr; TSK rules + inference + LSE fitting.</span><br>
&boxvr;&horbar; <span class="f">training.py</span> <span class="ds">&larr; Hybrid learning loop.</span><br>
&boxvr;&horbar; <span class="f">evaluation.py</span> <span class="ds">&larr; RMSE computation + table printer.</span><br>
&boxvr;&horbar; <span class="f">main.py</span> <span class="ds">&larr; Entry point: orchestrates everything.</span><br>
&boxvr;&horbar; <span class="f">predict.py</span> <span class="ds">&larr; Interactive CLI for end-user predictions.</span><br>
&boxvr;&horbar; <span class="f">requirements.txt</span> <span class="ds">&larr; numpy, pandas, openpyxl, scikit-learn.</span><br>
&boxvr;&horbar; <span class="d">data/</span> <span class="ds">&larr; Excel dataset goes here.</span><br>
&boxur;&horbar; <span class="d">output/</span> <span class="ds">&larr; Trained models + RMSE results.</span>
</div>
<div class="bx bx-c"><div class="bt">Modular Design</div><p>Each file has <strong>one responsibility</strong>. Change the clustering? Edit only <code>clustering.py</code>. Change the MF shape? Only <code>membership_functions.py</code>. This separation makes the code easy to understand, test, and modify.</p></div>

<h4>config.py &mdash; Why it exists</h4>
<p>Centralises every tuneable number. No magic numbers scattered in the code. Change <code>CLUSTER_RADIUS</code> here and it affects the entire system. <code>RANDOM_SEED = 42</code> makes results reproducible.</p>

<h4>data_loader.py &mdash; Why it exists</h4>
<p>The Excel file has a non-standard header (3 rows before data). This module encapsulates that messiness. It also provides <code>DataNormaliser</code>, which fits on training data only to prevent information leakage from the test set.</p>

<h4>evaluation.py &mdash; Why it exists</h4>
<p>Contains the RMSE formula: <code>sqrt(mean((y - &ycirc;)&sup2;))</code>. Separated so it can be reused anywhere without importing heavy modules.</p>

<h4>predict.py &mdash; Why it exists</h4>
<p>After training, this lets an end-user type in 10 input values and get predictions. It loads the trained model from <code>output/trained_systems.pkl</code>. You do <strong>not</strong> need to retrain every time.</p>

<h2 id="s8"><span class="sn">8</span> Code Walkthrough: main.py</h2>
<p><code>main.py</code> is the conductor that orchestrates the entire pipeline in 5 steps:</p>

<details><summary>&#128196; View Code &mdash; main.py (entry point)</summary><div class="db">
<div class="cw"><div class="ch"><span class="cf">main.py</span><span class="cl">Python</span></div>
<pre><code><span class="kw">def</span> <span class="fn">main</span>():
    np.random.seed(RANDOM_SEED)

    <span class="cm"># 1. Load &amp; split</span>
    df = load_raw_data()           <span class="cm"># 168 samples</span>
    X_train, X_test, y_train, y_test = split_data(df)

    <span class="cm"># 2. Normalise</span>
    normaliser = DataNormaliser()
    normaliser.fit(X_train, y_train)  <span class="cm"># fit on TRAIN only</span>
    X_tr = normaliser.transform_X(X_train)
    X_te = normaliser.transform_X(X_test)
    y_tr = normaliser.transform_y(y_train)

    <span class="cm"># 3. Build &amp; tune 4 TSK systems</span>
    <span class="kw">for</span> output_name <span class="kw">in</span> OUTPUT_COLUMNS:
        system = build_tsk_system(X_tr, y_tr[:, idx])
        history = tune_tsk_system(system, X_tr, y_tr[:, idx])

    <span class="cm"># 4. Evaluate (RMSE in original scale)</span>
    y_pred = system.predict(X_te)
    y_pred_orig = normaliser.inverse_transform(y_pred)
    rmse_test = sqrt(mean((y_test - y_pred_orig)**2))

    <span class="cm"># 5. Save models + results to output/</span>
    pickle.dump(systems, open("output/trained_systems.pkl", "wb"))
    json.dump(rmse_results, open("output/rmse_results.json", "w"))</code></pre></div>
<p>Notice Step 2: the normaliser is fit on training data only. This is critical &mdash; using test data in normalisation would leak future information into the model (a common beginner mistake).</p>
</div></details>

<h2 id="s9"><span class="sn">9</span> The Training Pipeline (Pseudocode)</h2>
<p>Here is the complete algorithm in plain English:</p>
<div class="cw"><div class="ch"><span class="cf">Pseudocode</span><span class="cl">Plain English</span></div>
<pre><code>FOR each output variable (Stability, Flow, ITSM20, ITSM30):
    1. Concatenate normalised inputs + this output &rarr; joint matrix
    2. Run subtractive clustering on joint matrix
       &rarr; produces K cluster centres (K &asymp; 11&ndash;12)
    3. Create K TSK rules:
       - Antecedent centres = input projection of cluster centre
       - Antecedent spreads = r_a / &radic;8
       - Consequent params  = random (will be overwritten)
    4. Estimate consequent params via ridge regression (LSE)
    5. FOR epoch = 1 to 800:
       a. Forward pass: compute prediction for all training samples
       b. Compute RMSE; if converged, stop
       c. Backward pass: compute gradients for each rule's c and &sigma;
       d. Update c and &sigma; by gradient descent (lr = 0.01)
       e. Re-estimate consequent params via LSE
    6. Evaluate: compute RMSE on TRAIN and TEST sets</code></pre></div>

<h2 id="s10"><span class="sn">10</span> Results &amp; RMSE</h2>
<p>After training with r_a = 1.2, 800 epochs, lr = 0.01:</p>
<table>
<tr><th>Output</th><th>Rules</th><th>RMSE (Train)</th><th>RMSE (Test)</th><th>Test/Train Ratio</th></tr>
<tr><td><strong>Stability</strong> (kN)</td><td>12</td><td>0.7574</td><td>1.0574</td><td>1.40</td></tr>
<tr><td><strong>Flow</strong> (mm)</td><td>11</td><td>0.5771</td><td>0.7848</td><td>1.36</td></tr>
<tr><td><strong>ITSM 20&deg;C</strong> (MPa)</td><td>11</td><td>401.31</td><td>576.67</td><td>1.44</td></tr>
<tr><td><strong>ITSM 30&deg;C</strong> (MPa)</td><td>11</td><td>121.91</td><td>184.55</td><td>1.51</td></tr>
</table>
<div class="bx bx-k"><div class="bt">&#128273; Interpreting the Results</div>
<p><strong>Test/Train Ratio &asymp; 1.4&ndash;1.5</strong> means the system generalises well &mdash; it is not memorising training data. The ITSM outputs have larger absolute RMSE because their scale is much larger (100s&ndash;1000s of MPa). When normalised, all four outputs have comparable relative error.</p></div>

<div class="bx bx-w"><div class="bt">What if results were bad?</div>
<p>If Test RMSE were 10&times; Train RMSE, that would signal <strong>overfitting</strong>. Solutions: increase r_a (fewer rules), increase &lambda; (more regularisation), or get more training data.</p></div>

<h2 id="s11"><span class="sn">11</span> How to Run the Code</h2>
<h3>Step 1: Install Python packages</h3>
<div class="cw"><div class="ch"><span class="cf">Terminal</span><span class="cl">Bash</span></div>
<pre><code>pip install -r requirements.txt</code></pre></div>
<p>This installs: <code>numpy</code> (numerical arrays), <code>pandas</code> + <code>openpyxl</code> (Excel reading), <code>scikit-learn</code> (MinMaxScaler, train_test_split).</p>

<h3>Step 2: Place the dataset</h3>
<p>Put <code>Asphalt-Dataset-ToClass.xlsx</code> into the <code>data/</code> folder.</p>

<h3>Step 3: Train</h3>
<div class="cw"><div class="ch"><span class="cf">Terminal</span><span class="cl">Bash</span></div>
<pre><code>python main.py</code></pre></div>
<p>This trains 4 TSK systems and saves results to <code>output/</code>.</p>

<h3>Step 4: Predict (end-user mode)</h3>
<div class="cw"><div class="ch"><span class="cf">Terminal</span><span class="cl">Bash</span></div>
<pre><code>python predict.py</code></pre></div>
<p>Enter 10 input values when prompted. The system returns predictions for all 4 outputs.</p>

<div class="bx bx-c"><div class="bt">&#127891; What You Have Learned</div>
<p>You now understand: what fuzzy sets are, how Gaussian MFs work, how TSK rules combine linear functions with fuzzy logic, how subtractive clustering discovers rules from data, how hybrid learning (LSE + gradient descent) optimises the system, and how all the Python files work together. You can rebuild this system from scratch.</p></div>

</main>

<script>
/* ═══════════════════════════════════════════════
   Progress tracking with localStorage
   ═══════════════════════════════════════════════ */
const TOTAL = 12;
const KEY = 'tsk_study_progress';

function loadProgress() {
  try {
    const stored = localStorage.getItem(KEY);
    return stored ? JSON.parse(stored) : {};
  } catch(e) { return {}; }
}

function saveProgress(state) {
  try { localStorage.setItem(KEY, JSON.stringify(state)); } catch(e) {}
}

function updateUI() {
  const state = loadProgress();
  let done = 0;
  document.querySelectorAll('.nav-check').forEach(el => {
    const idx = el.dataset.idx;
    if (state[idx]) {
      el.classList.add('checked');
      done++;
    } else {
      el.classList.remove('checked');
    }
  });
  document.getElementById('progress-text').textContent = done + ' / ' + TOTAL + ' complete';
  document.getElementById('progress-bar').style.width = (done / TOTAL * 100) + '%';
}

document.querySelectorAll('.nav-check').forEach(el => {
  el.addEventListener('click', function(e) {
    e.preventDefault();
    e.stopPropagation();
    const idx = this.dataset.idx;
    const state = loadProgress();
    state[idx] = !state[idx];
    saveProgress(state);
    updateUI();
  });
});

// Highlight active section on scroll
const sections = [];
document.querySelectorAll('h2[id]').forEach(h => sections.push(h));
const navItems = document.querySelectorAll('.nav-item');

function highlightNav() {
  let current = '';
  sections.forEach(sec => {
    if (window.scrollY >= sec.offsetTop - 120) current = sec.id;
  });
  navItems.forEach(item => {
    item.classList.toggle('active', item.getAttribute('href') === '#' + current);
  });
}
window.addEventListener('scroll', highlightNav, {passive: true});

updateUI();
highlightNav();
</script>
</body>
</html>
